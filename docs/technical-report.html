<!DOCTYPE html>
<html lang="en" prefix="schema: http://schema.org/">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BiR - Technical Report | Big Data Retriever</title>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/scholarly-html@1.0.0/scholarly.min.css">
    <style>
        body {
            max-width: 900px;
            margin: 0 auto;
            padding: 2em;
            font-family: 'Georgia', serif;
            line-height: 1.6;
        }
        h1, h2, h3 {
            color: #2c3e50;
            margin-top: 1.5em;
        }
        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
        }
        pre {
            background: #f4f4f4;
            padding: 1em;
            border-radius: 5px;
            overflow-x: auto;
        }
        table {
            border-collapse: collapse;
            width: 100%;
            margin: 1em 0;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 8px;
            text-align: left;
        }
        th {
            background-color: #4CAF50;
            color: white;
        }
        .sparql-query {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 1em;
            border-radius: 5px;
            overflow-x: auto;
        }
        .sparql-query .keyword { color: #c678dd; }
        .sparql-query .string { color: #98c379; }
        .sparql-query .comment { color: #5c6370; }
        figure {
            margin: 2em 0;
            text-align: center;
        }
        figure img {
            display: block;
            margin: 0 auto;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }
        figcaption {
            margin-top: 1em;
            font-style: italic;
            color: #555;
            text-align: left;
            padding: 0 1em;
        }
        h5 {
            color: #34495e;
            margin-top: 2em;
        }
    </style>
</head>
<body>
    <header>
        <h1>BiR - Big Data Retriever</h1>
        <h2>Technical Report</h2>
        <div role="contentinfo">
            <dl>
                <dt>Authors</dt>
                <dd>BiR Development Team</dd>
                <dt>Date</dt>
                <dd>January 2025</dd>
                <dt>Version</dt>
                <dd>1.0</dd>
            </dl>
        </div>
    </header>

    <section id="abstract">
        <h2>Abstract</h2>
        <p>
            This technical report describes the implementation details of BiR (Big Data Retriever), 
            a microservices-based platform that extracts data from Wikidata to build a local Knowledge Graph 
            for Music and Fine Arts domains. The system uses RDF data models based on Schema.org vocabulary, 
            SPARQL queries for data extraction and interrogation, and Apache Spark for distributed data processing. 
            This document covers internal data structures, REST API implementation, RDF knowledge modeling, 
            external data source integration, and Linked Data principles conformance.
        </p>
    </section>

    <section id="introduction">
        <h2>1. Introduction</h2>
        <p>
            BiR is a Web application that demonstrates the practical use of semantic web technologies 
            for building knowledge graphs from open data sources. The system processes data from Wikidata, 
            transforms it into RDF format using Schema.org vocabulary, and stores it in a local Knowledge Graph 
            using Apache Jena Fuseki. The platform provides RESTful APIs for querying and analyzing the data, 
            with support for both Music and Fine Arts domains.
        </p>
        <p>
            The architecture follows microservices principles, with separate services for data extraction (SPARQL Service), 
            analytics (Analytics Service), recommendations (Recommendation Service), and API routing (API Gateway). 
            The frontend is built with React and provides interactive visualizations of the Knowledge Graph data.
        </p>
    </section>

    <section id="data-structures">
        <h2>2. Internal Data Structures and Models</h2>
        
        <section id="data-structures-overview">
            <h3>2.1 Overview</h3>
            <p>
                The system manages data in multiple formats throughout the processing pipeline:
            </p>
            <ul>
                <li><strong>JSON</strong>: Initial data from Wikidata SPARQL queries</li>
                <li><strong>RDF Triples</strong>: Transformed data stored in Fuseki Knowledge Graph</li>
                <li><strong>JSON (Cached)</strong>: Fast-access data stored in Redis</li>
                <li><strong>Parquet</strong>: Analytics data stored in the data lake</li>
            </ul>
        </section>

        <section id="music-data-model">
            <h3>2.2 Music Domain Data Model</h3>
            <p>
                The Music domain represents music bands and their properties. The internal data structure 
                follows the Schema.org MusicGroup vocabulary.
            </p>
            
            <h4>2.2.1 JSON Structure (Redis Cache)</h4>
            <pre><code>{
  "id": "http://www.wikidata.org/entity/Q1299",
  "name": "The Beatles",
  "genre": "Rock",
  "country": "United Kingdom",
  "year": "1960"
}</code></pre>

            <h4>2.2.2 RDF Structure (Fuseki Knowledge Graph)</h4>
            <div class="sparql-query">
&lt;http://www.wikidata.org/entity/Q1299&gt; 
  a schema:MusicGroup ;
  schema:name "The Beatles" ;
  schema:genre "Rock" ;
  schema:location "United Kingdom" ;
  dbpedia:activeYearsStartYear 1960 ;
  schema:member "John Lennon" ;
  schema:member "Paul McCartney" ;
  schema:award "Grammy Award" .
            </div>

            <h4>2.2.3 Python Data Model</h4>
            <p>
                In the Python backend services, music bands are represented as dictionaries:
            </p>
            <pre><code>{
    'band': {'value': 'http://www.wikidata.org/entity/Q1299'},
    'bandLabel': {'value': 'The Beatles'},
    'genreLabel': {'value': 'Rock'},
    'countryLabel': {'value': 'United Kingdom'},
    'startYear': {'value': '1960'},
    'memberLabel': {'value': 'John Lennon'},
    'awardLabel': {'value': 'Grammy Award'}
}</code></pre>
        </section>

        <section id="art-data-model">
            <h3>2.3 Fine Arts Domain Data Model</h3>
            <p>
                The Fine Arts domain represents visual artworks (paintings, sculptures, drawings, prints) 
                and their properties using Schema.org VisualArtwork vocabulary.
            </p>

            <h4>2.3.1 JSON Structure (Redis Cache)</h4>
            <pre><code>{
  "id": "http://www.wikidata.org/entity/Q12418",
  "name": "The Starry Night",
  "type": "painting",
  "creator": "Vincent van Gogh",
  "movement": "Post-Impressionism",
  "country": "France",
  "date": "1889",
  "material": "oil on canvas",
  "location": "Museum of Modern Art"
}</code></pre>

            <h4>2.3.2 RDF Structure (Fuseki Knowledge Graph)</h4>
            <div class="sparql-query">
&lt;http://www.wikidata.org/entity/Q12418&gt; 
  a schema:VisualArtwork ;
  schema:name "The Starry Night" ;
  schema:artform "painting" ;
  schema:creator "Vincent van Gogh" ;
  schema:artMovement "Post-Impressionism" ;
  schema:locationCreated "France" ;
  schema:dateCreated "1889" ;
  schema:material "oil on canvas" ;
  schema:contentLocation "Museum of Modern Art" .
            </div>
        </section>

        <section id="data-transformation">
            <h3>2.4 Data Transformation Pipeline</h3>
            <p>
                Data flows through the following transformation stages:
            </p>
            <ol>
                <li><strong>Extract</strong>: SPARQL query to Wikidata returns JSON bindings</li>
                <li><strong>Transform</strong>: JSON bindings converted to RDF triples using Schema.org vocabulary</li>
                <li><strong>Load</strong>: 
                    <ul>
                        <li>RDF triples inserted into Fuseki Knowledge Graph</li>
                        <li>Simplified JSON objects stored in Redis for fast search</li>
                    </ul>
                </li>
            </ol>

            <p>
                The transformation function <code>transform_to_rdf()</code> in the SPARQL Service 
                converts each Wikidata result binding into RDF triples:
            </p>
            <pre><code>def transform_to_rdf(item):
    s = f"&lt;{item['band']['value']}&gt;"
    triples = []
    triples.append(f'{s} a schema:MusicGroup .')
    triples.append(f'{s} schema:name "{clean(item["bandLabel"]["value"])}" .')
    triples.append(f'{s} schema:genre "{clean(item["genreLabel"]["value"])}" .')
    # ... additional properties
    return "\n".join(triples)</code></pre>
        </section>
    </section>

    <section id="api-implementation">
        <h2>3. REST API Technical Implementation</h2>
        
        <section id="api-architecture">
            <h3>3.1 API Architecture</h3>
            <p>
                The API follows a microservices architecture with an API Gateway pattern. 
                All client requests are routed through the API Gateway, which forwards them 
                to the appropriate microservice.
            </p>
            <p>
                <strong>API Gateway</strong> (Port 8000): Single entry point for all API requests
            </p>
            <p>
                <strong>Microservices</strong>:
            </p>
            <ul>
                <li>SPARQL Service (Port 8001): Data extraction and search</li>
                <li>Analytics Service (Port 8002): Statistics and analytics</li>
                <li>Recommendation Service (Port 8003): Similarity recommendations</li>
            </ul>

            <h4>3.1.1 Architecture Diagrams (C4 Model)</h4>
            <p>
                The following diagrams illustrate the BiR system architecture at different levels of abstraction,
                following the C4 Model approach (Context, Container, Component, Code).
            </p>

            <h5>Level 1: System Context Diagram</h5>
            <figure>
                <img src="c4-context-diagram.png" alt="BiR System Context Diagram showing end users, BiR Web Application, and external systems (Wikidata, Redis, Fuseki)" style="width: 100%; max-width: 600px; border: 1px solid #ddd; padding: 10px; background: white;">
                <figcaption>
                    <strong>Figure 1</strong>: System Context - Shows how end users (researchers, students, art historians,
                    music enthusiasts) interact with the BiR Web Application, which in turn communicates with external
                    systems: Wikidata SPARQL API for data extraction, Redis for caching, and Fuseki for RDF Knowledge Graph storage.
                </figcaption>
            </figure>

            <h5>Level 3: SPARQL Service Component Diagram</h5>
            <figure>
                <img src="c4-sparql-component.png" alt="SPARQL Service Container showing ETL Pipeline, RDF Transformer, Search Component, and Wikidata Client" style="width: 100%; max-width: 700px; border: 1px solid #ddd; padding: 10px; background: white;">
                <figcaption>
                    <strong>Figure 2</strong>: SPARQL Service Components - Detailed view of the SPARQL Service container showing
                    the ETL Pipeline (Extract from Wikidata, Transform to RDF, Load to Redis & Fuseki), RDF Transformer
                    (JSON to RDF conversion with Schema.org mapping), Search Component (Music and Art search via Redis),
                    and Wikidata Client (SPARQL query execution and result parsing).
                </figcaption>
            </figure>

            <h5>Level 3: Analytics Service Component Diagram</h5>
            <figure>
                <img src="c4-analytics-component.png" alt="Analytics Service Container showing Statistics, Influence Discovery, Natural Language Search, Comparison, and Spark Engine components" style="width: 100%; max-width: 800px; border: 1px solid #ddd; padding: 10px; background: white;">
                <figcaption>
                    <strong>Figure 3</strong>: Analytics Service Components - Shows the Analytics Service architecture with
                    Statistics component (global stats, top countries/genres), Influence Discovery (band influence,
                    movement relationships), Natural Language Search (query parsing, SPARQL generation), Comparison
                    (time period, country/genre comparison), and the central Spark Engine for distributed processing,
                    transformations, and aggregations. The service queries Fuseki and writes results to the Data Lake (Parquet format).
                </figcaption>
            </figure>

            <p>
                <strong>Note</strong>: Complete C4 Model documentation with all levels (Context, Container, Component, Code)
                and additional diagrams is available in <code>docs/C4_MODEL.md</code>.
            </p>
        </section>

        <section id="api-endpoints">
            <h3>3.2 API Endpoints</h3>
            
            <h4>3.2.1 Music Endpoints</h4>
            <table>
                <tr>
                    <th>Endpoint</th>
                    <th>Method</th>
                    <th>Description</th>
                    <th>Service</th>
                </tr>
                <tr>
                    <td><code>/api/music</code></td>
                    <td>GET</td>
                    <td>Search bands by name or genre</td>
                    <td>SPARQL Service</td>
                </tr>
                <tr>
                    <td><code>/api/stats</code></td>
                    <td>GET</td>
                    <td>Get global statistics</td>
                    <td>Analytics Service</td>
                </tr>
                <tr>
                    <td><code>/api/influences</code></td>
                    <td>GET</td>
                    <td>Discover band influences</td>
                    <td>Analytics Service</td>
                </tr>
                <tr>
                    <td><code>/api/recommend</code></td>
                    <td>GET</td>
                    <td>Get band recommendations</td>
                    <td>Recommendation Service</td>
                </tr>
            </table>

            <h4>3.2.2 Fine Arts Endpoints</h4>
            <table>
                <tr>
                    <th>Endpoint</th>
                    <th>Method</th>
                    <th>Description</th>
                    <th>Service</th>
                </tr>
                <tr>
                    <td><code>/api/art</code></td>
                    <td>GET</td>
                    <td>Search artworks</td>
                    <td>SPARQL Service</td>
                </tr>
                <tr>
                    <td><code>/api/art/stats</code></td>
                    <td>GET</td>
                    <td>Get art statistics</td>
                    <td>Analytics Service</td>
                </tr>
                <tr>
                    <td><code>/api/art/influences</code></td>
                    <td>GET</td>
                    <td>Get artworks by movement</td>
                    <td>Analytics Service</td>
                </tr>
                <tr>
                    <td><code>/api/art/recommend</code></td>
                    <td>GET</td>
                    <td>Get artwork recommendations</td>
                    <td>Recommendation Service</td>
                </tr>
            </table>
        </section>

        <section id="api-implementation-details">
            <h3>3.3 Implementation Details</h3>
            
            <h4>3.3.1 Request Routing</h4>
            <p>
                The API Gateway uses Flask routing to forward requests:
            </p>
            <pre><code>@app.route('/api/music', methods=['GET'])
def music():
    try: 
        return jsonify(requests.get(
            f"{SPARQL}/search/music", 
            params=request.args
        ).json())
    except: 
        return jsonify([]), 503</code></pre>

            <h4>3.3.2 Error Handling</h4>
            <p>
                All endpoints implement try-except blocks to handle service unavailability. 
                When a downstream service is unavailable, the API Gateway returns a 503 status code 
                with an empty response or error message.
            </p>

            <h4>3.3.3 CORS Configuration</h4>
            <p>
                Cross-Origin Resource Sharing (CORS) is enabled on all services to allow 
                the frontend to make requests from the browser:
            </p>
            <pre><code>from flask_cors import CORS
app = Flask(__name__)
CORS(app)</code></pre>

            <h4>3.3.4 Response Format</h4>
            <p>
                All API responses are in JSON format. Success responses return HTTP 200 
                with JSON data. Error responses return appropriate HTTP status codes 
                (400, 404, 503) with error messages.
            </p>
        </section>

        <section id="api-performance">
            <h3>3.4 Performance Considerations</h3>
            <ul>
                <li><strong>Caching</strong>: Search results are cached in Redis for fast retrieval</li>
                <li><strong>Connection Pooling</strong>: Redis connections are reused</li>
                <li><strong>Batch Processing</strong>: RDF triples are inserted in batches of 500</li>
                <li><strong>Async Processing</strong>: ETL pipeline runs in background threads</li>
            </ul>
        </section>
    </section>

    <section id="rdf-knowledge-model">
        <h2>4. RDF-Based Knowledge Model</h2>
        
        <section id="vocabulary-selection">
            <h3>4.1 Vocabulary Selection: Schema.org</h3>
            <p>
                The system uses Schema.org vocabulary for representing data in RDF format. 
                Schema.org was chosen because:
            </p>
            <ul>
                <li>It is a widely adopted standard for structured data on the web</li>
                <li>It provides comprehensive coverage for Music and Arts domains</li>
                <li>It supports Linked Data principles with well-defined URIs</li>
                <li>It is compatible with major search engines and knowledge bases</li>
            </ul>
        </section>

        <section id="music-vocabulary">
            <h3>4.2 Music Domain Vocabulary</h3>
            <p>
                For the Music domain, we use the following Schema.org classes and properties:
            </p>
            <table>
                <tr>
                    <th>Class/Property</th>
                    <th>URI</th>
                    <th>Usage</th>
                </tr>
                <tr>
                    <td>MusicGroup</td>
                    <td><code>http://schema.org/MusicGroup</code></td>
                    <td>Type for music bands</td>
                </tr>
                <tr>
                    <td>name</td>
                    <td><code>http://schema.org/name</code></td>
                    <td>Band name</td>
                </tr>
                <tr>
                    <td>genre</td>
                    <td><code>http://schema.org/genre</code></td>
                    <td>Music genre</td>
                </tr>
                <tr>
                    <td>location</td>
                    <td><code>http://schema.org/location</code></td>
                    <td>Country of origin</td>
                </tr>
                <tr>
                    <td>member</td>
                    <td><code>http://schema.org/member</code></td>
                    <td>Band members</td>
                </tr>
                <tr>
                    <td>award</td>
                    <td><code>http://schema.org/award</code></td>
                    <td>Awards received</td>
                </tr>
            </table>
            <p>
                Additionally, we use <code>dbpedia:activeYearsStartYear</code> from DBpedia ontology 
                for the founding year, as Schema.org does not have a direct property for this.
            </p>
        </section>

        <section id="art-vocabulary">
            <h3>4.3 Fine Arts Domain Vocabulary</h3>
            <p>
                For the Fine Arts domain, we use Schema.org VisualArtwork vocabulary:
            </p>
            <table>
                <tr>
                    <th>Class/Property</th>
                    <th>URI</th>
                    <th>Usage</th>
                </tr>
                <tr>
                    <td>VisualArtwork</td>
                    <td><code>http://schema.org/VisualArtwork</code></td>
                    <td>Type for artworks</td>
                </tr>
                <tr>
                    <td>name</td>
                    <td><code>http://schema.org/name</code></td>
                    <td>Artwork title</td>
                </tr>
                <tr>
                    <td>artform</td>
                    <td><code>http://schema.org/artform</code></td>
                    <td>Type (painting, sculpture, etc.)</td>
                </tr>
                <tr>
                    <td>creator</td>
                    <td><code>http://schema.org/creator</code></td>
                    <td>Artist name</td>
                </tr>
                <tr>
                    <td>artMovement</td>
                    <td><code>http://schema.org/artMovement</code></td>
                    <td>Art movement</td>
                </tr>
                <tr>
                    <td>locationCreated</td>
                    <td><code>http://schema.org/locationCreated</code></td>
                    <td>Country where created</td>
                </tr>
                <tr>
                    <td>dateCreated</td>
                    <td><code>http://schema.org/dateCreated</code></td>
                    <td>Creation date</td>
                </tr>
                <tr>
                    <td>material</td>
                    <td><code>http://schema.org/material</code></td>
                    <td>Material/medium used</td>
                </tr>
                <tr>
                    <td>contentLocation</td>
                    <td><code>http://schema.org/contentLocation</code></td>
                    <td>Current museum/location</td>
                </tr>
            </table>
        </section>

        <section id="vocabulary-expressiveness">
            <h3>4.4 Expressiveness and Real Usage</h3>
            <p>
                The Schema.org vocabulary provides sufficient expressiveness for our use cases:
            </p>
            <ul>
                <li><strong>Type System</strong>: Clear distinction between MusicGroup and VisualArtwork</li>
                <li><strong>Properties</strong>: Comprehensive coverage of relevant attributes</li>
                <li><strong>Extensibility</strong>: Can be extended with additional properties if needed</li>
                <li><strong>Interoperability</strong>: Compatible with other Schema.org-based systems</li>
            </ul>
            <p>
                The vocabulary is actively used in production:
            </p>
            <ul>
                <li>All RDF triples in Fuseki use Schema.org URIs</li>
                <li>Frontend components include Schema.org JSON-LD markup</li>
                <li>Resource URLs follow Linked Data principles</li>
            </ul>
        </section>

        <section id="ontology-design-patterns">
            <h3>4.5 Ontology Design Patterns</h3>
            <p>
                The knowledge model follows several ontology design patterns:
            </p>
            <ul>
                <li><strong>Type-Token Pattern</strong>: Each band/artwork is a unique instance (token) of a type (MusicGroup/VisualArtwork)</li>
                <li><strong>Property Reification</strong>: Properties are directly attached to resources</li>
                <li><strong>Vocabulary Reuse</strong>: Reusing Schema.org instead of creating custom vocabulary</li>
                <li><strong>Linked Data Pattern</strong>: Resources identified by HTTP URIs</li>
            </ul>
        </section>
    </section>

    <section id="external-data-sources">
        <h2>5. External Data Sources and Knowledge Bases</h2>
        
        <section id="wikidata-integration">
            <h3>5.1 Wikidata Integration</h3>
            <p>
                Wikidata is the primary external data source for the system. It is a free, 
                collaborative, multilingual knowledge base that contains structured data 
                from Wikipedia and other sources.
            </p>
            
            <h4>5.1.1 Wikidata SPARQL Endpoint</h4>
            <p>
                The system queries Wikidata using its public SPARQL endpoint:
            </p>
            <pre><code>https://query.wikidata.org/sparql</code></pre>
            
            <h4>5.1.2 SPARQL Query Example - Music Domain</h4>
            <div class="sparql-query">
PREFIX wdt: &lt;http://www.wikidata.org/prop/direct/&gt;
PREFIX wd: &lt;http://www.wikidata.org/entity/&gt;
PREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;

SELECT DISTINCT ?band ?bandLabel ?genreLabel ?countryLabel 
                ?startYear ?memberLabel ?awardLabel
WHERE {
  ?band wdt:P31 wd:Q215380 .  # Music group
  ?band rdfs:label ?bandLabel . 
  FILTER(LANG(?bandLabel) = "en")
  
  OPTIONAL { ?band wdt:P136 ?genre . 
             ?genre rdfs:label ?genreLabel . 
             FILTER(LANG(?genreLabel) = "en") }
  
  OPTIONAL { ?band wdt:P495 ?country . 
             ?country rdfs:label ?countryLabel . 
             FILTER(LANG(?countryLabel) = "en") }
  
  OPTIONAL { ?band wdt:P571 ?startYear . }
  OPTIONAL { ?band wdt:P527 ?member . 
             ?member rdfs:label ?memberLabel . 
             FILTER(LANG(?memberLabel) = "en") }
  OPTIONAL { ?band wdt:P166 ?award . 
             ?award rdfs:label ?awardLabel . 
             FILTER(LANG(?awardLabel) = "en") }
}
LIMIT 1000
            </div>

            <h4>5.1.3 SPARQL Query Example - Fine Arts Domain</h4>
            <div class="sparql-query">
PREFIX wdt: &lt;http://www.wikidata.org/prop/direct/&gt;
PREFIX wd: &lt;http://www.wikidata.org/entity/&gt;
PREFIX rdfs: &lt;http://www.w3.org/2000/01/rdf-schema#&gt;

SELECT DISTINCT ?artwork ?artworkLabel ?typeLabel ?creatorLabel
                ?movementLabel ?countryLabel ?date 
                ?materialLabel ?locationLabel
WHERE {
  VALUES ?type { wd:Q3305213 wd:Q860861 wd:Q93184 wd:Q11060274 }
  ?artwork wdt:P31 ?type .  # Painting, Sculpture, Drawing, Print
  ?artwork rdfs:label ?artworkLabel . 
  FILTER(LANG(?artworkLabel) = "en")
  
  OPTIONAL { ?artwork wdt:P170 ?creator . 
             ?creator rdfs:label ?creatorLabel . 
             FILTER(LANG(?creatorLabel) = "en") }
  
  OPTIONAL { ?artwork wdt:P135 ?movement . 
             ?movement rdfs:label ?movementLabel . 
             FILTER(LANG(?movementLabel) = "en") }
  
  OPTIONAL { ?artwork wdt:P495 ?country . 
             ?country rdfs:label ?countryLabel . 
             FILTER(LANG(?countryLabel) = "en") }
  
  OPTIONAL { ?artwork wdt:P571 ?date . }
  OPTIONAL { ?artwork wdt:P186 ?material . 
             ?material rdfs:label ?materialLabel . 
             FILTER(LANG(?materialLabel) = "en") }
  OPTIONAL { ?artwork wdt:P276 ?location . 
             ?location rdfs:label ?locationLabel . 
             FILTER(LANG(?locationLabel) = "en") }
}
LIMIT 3000
            </div>
        </section>

        <section id="non-trivial-queries">
            <h3>5.2 Non-Trivial SPARQL Queries</h3>
            
            <h4>5.2.1 Influence Discovery Query</h4>
            <p>
                This query discovers bands and their influences within a specific country and time period:
            </p>
            <div class="sparql-query">
PREFIX schema: &lt;http://schema.org/&gt;
PREFIX dbpedia: &lt;http://dbpedia.org/ontology/&gt;

SELECT ?band ?bandName ?influenceName
WHERE {
  ?band a schema:MusicGroup .
  ?band schema:name ?bandName .
  ?band schema:location ?country .
  ?band dbpedia:activeYearsStartYear ?year .
  
  FILTER (contains(lcase(str(?country)), "united kingdom"))
  FILTER (?year >= 1980 && ?year <= 2000)
  
  OPTIONAL {
    ?band schema:influencedBy ?influence .
    ?influence schema:name ?influenceName .
  }
}
ORDER BY ?bandName
            </div>

            <h4>5.2.2 Art Movement Analysis Query</h4>
            <p>
                This query analyzes artworks by movement and country:
            </p>
            <div class="sparql-query">
PREFIX schema: &lt;http://schema.org/&gt;

SELECT ?movement ?country (COUNT(?artwork) AS ?count)
WHERE {
  ?artwork a schema:VisualArtwork .
  ?artwork schema:artMovement ?movement .
  ?artwork schema:locationCreated ?country .
}
GROUP BY ?movement ?country
ORDER BY DESC(?count)
LIMIT 20
            </div>

            <h4>5.2.3 Similarity Recommendation Query</h4>
            <p>
                This query finds similar bands based on genre and country:
            </p>
            <div class="sparql-query">
PREFIX schema: &lt;http://schema.org/&gt;

SELECT ?similarBand ?similarName ?genre ?country
WHERE {
  # Find the target band
  ?target a schema:MusicGroup .
  ?target schema:name "The Beatles" .
  ?target schema:genre ?targetGenre .
  ?target schema:location ?targetCountry .
  
  # Find similar bands
  ?similarBand a schema:MusicGroup .
  ?similarBand schema:name ?similarName .
  ?similarBand schema:genre ?genre .
  ?similarBand schema:location ?country .
  
  FILTER (?similarBand != ?target)
  FILTER (?genre = ?targetGenre || ?country = ?targetCountry)
}
LIMIT 10
            </div>
        </section>

        <section id="dbpedia-usage">
            <h3>5.3 DBpedia Usage</h3>
            <p>
                While the primary data source is Wikidata, the system also references DBpedia ontology 
                for certain properties:
            </p>
            <ul>
                <li><code>dbpedia:activeYearsStartYear</code>: Used for band founding year (not available in Schema.org)</li>
            </ul>
            <p>
                Future enhancements could include direct DBpedia queries for additional data enrichment.
            </p>
        </section>

        <section id="data-quality">
            <h3>5.4 Data Quality and Processing</h3>
            <p>
                Data from Wikidata is processed to ensure quality:
            </p>
            <ul>
                <li><strong>Text Cleaning</strong>: Special characters, newlines, and quotes are escaped for RDF insertion</li>
                <li><strong>Deduplication</strong>: Spark transformations remove duplicate entries</li>
                <li><strong>Validation</strong>: URIs are validated before insertion</li>
                <li><strong>Language Filtering</strong>: Only English labels are extracted (with support for Romanian and French)</li>
            </ul>
        </section>
    </section>

    <section id="linked-data-principles">
        <h2>6. Linked Data Principles Conformance</h2>
        
        <section id="principle-1">
            <h3>6.1 Principle 1: Use URIs as Names for Things</h3>
            <p>
                <strong>Conformance</strong>: All resources are identified by HTTP URIs.
            </p>
            <ul>
                <li>Music bands use Wikidata URIs: <code>http://www.wikidata.org/entity/Q1299</code></li>
                <li>Artworks use Wikidata URIs: <code>http://www.wikidata.org/entity/Q12418</code></li>
                <li>Resource URLs are generated: <code>http://localhost:5173/resource/music/{encoded-id}</code></li>
            </ul>
        </section>

        <section id="principle-2">
            <h3>6.2 Principle 2: Use HTTP URIs so People can Look them Up</h3>
            <p>
                <strong>Conformance</strong>: All URIs are dereferenceable HTTP URIs.
            </p>
            <ul>
                <li>Wikidata URIs can be dereferenced to get RDF descriptions</li>
                <li>Resource URLs in the system can be accessed via HTTP</li>
                <li>QR codes are generated for each resource with its HTTP URI</li>
            </ul>
        </section>

        <section id="principle-3">
            <h3>6.3 Principle 3: When Someone Looks Up a URI, Provide Useful Information</h3>
            <p>
                <strong>Conformance</strong>: Resource URLs return useful information.
            </p>
            <ul>
                <li>Resource pages display full RDF data about the entity</li>
                <li>Schema.org JSON-LD markup is included in HTML</li>
                <li>RDFa attributes provide machine-readable data</li>
            </ul>
        </section>

        <section id="principle-4">
            <h3>6.4 Principle 4: Include Links to Other URIs</h3>
            <p>
                <strong>Conformance</strong>: Resources link to related entities.
            </p>
            <ul>
                <li>Bands link to their influences (via SPARQL queries)</li>
                <li>Artworks link to their creators and movements</li>
                <li>Network graphs visualize relationships between entities</li>
                <li>Recommendations provide links to similar resources</li>
            </ul>
        </section>

        <section id="linked-data-implementation">
            <h3>6.5 Implementation Details</h3>
            <p>
                The system implements Linked Data principles through:
            </p>
            <ul>
                <li><strong>RDF Storage</strong>: All data stored as RDF triples in Fuseki</li>
                <li><strong>SPARQL Endpoint</strong>: Fuseki provides SPARQL query endpoint at <code>/bir/query</code></li>
                <li><strong>Resource URLs</strong>: Each resource has a unique, shareable URL</li>
                <li><strong>URL Sharing</strong>: Fine Arts resources can be shared via generated URLs</li>
                <li><strong>Schema.org Markup</strong>: Frontend includes structured data</li>
            </ul>
            <p>
                <strong>Note</strong>: QR code generation utility exists (<code>frontend/src/utils/qrCode.js</code>) 
                but is not currently integrated in the user interface. Resource sharing is implemented via URLs 
                for Fine Arts domain.
            </p>
        </section>
    </section>

    <section id="big-data-spark">
        <h2>7. Big Data Processing with Apache Spark</h2>

        <section id="spark-architecture">
            <h3>7.1 Spark Architecture in BiR</h3>
            <p>
                The BiR platform leverages Apache Spark for distributed big data processing, particularly
                for ETL operations and real-time analytics queries. Spark is integrated into two main services:
            </p>
            <ul>
                <li><strong>Spark ETL Service</strong>: Handles large-scale data extraction, transformation, and loading</li>
                <li><strong>Analytics Service</strong>: Performs on-demand analytics using Spark DataFrames</li>
            </ul>

            <h4>7.1.1 SparkSession Configuration</h4>
            <p>
                The Spark environment is configured with specific memory and execution parameters:
            </p>
            <pre><code># Spark ETL Service Configuration
spark = SparkSession.builder \
    .appName("BiR-ArtETL") \
    .master("spark://spark-master:7077") \
    .config("spark.driver.memory", "1g") \
    .config("spark.executor.memory", "1g") \
    .getOrCreate()

# Analytics Service Configuration
spark = SparkSession.builder \
    .appName("BiR_Analytics_Engine") \
    .config("spark.driver.memory", "2g") \
    .config("spark.ui.showConsoleProgress", "false") \
    .getOrCreate()</code></pre>

            <p>
                <strong>Configuration rationale</strong>:
            </p>
            <ul>
                <li><strong>Driver Memory</strong>: 1-2GB allocated for the Spark driver process</li>
                <li><strong>Executor Memory</strong>: 1GB per executor for distributed tasks</li>
                <li><strong>Master URL</strong>: Configurable between local mode and distributed Spark cluster</li>
                <li><strong>UI Progress</strong>: Disabled in analytics service to reduce log verbosity</li>
            </ul>
        </section>

        <section id="spark-etl-pipeline">
            <h3>7.2 Spark ETL Pipeline</h3>
            <p>
                The ETL pipeline processes data from Wikidata through three distinct phases, leveraging
                Spark's distributed computing capabilities for efficient transformation and loading.
            </p>

            <h4>7.2.1 Extract Phase</h4>
            <p>
                Data is extracted from Wikidata via SPARQL queries, returning JSON bindings for 3000+ artworks:
            </p>
            <pre><code>def extract_from_wikidata(self):
    query = self.load_sparql_query("art_preload.sparql")
    results = self.sparql.query().convert()
    return results["results"]["bindings"]  # JSON list of 3000+ items</code></pre>

            <h4>7.2.2 Transform Phase with Spark</h4>
            <p>
                Raw JSON data is transformed using Spark DataFrames with explicit schema definition:
            </p>
            <pre><code>def transform_with_spark(self, raw_data):
    # 1. Define explicit schema
    schema = StructType([
        StructField("artwork", StringType(), True),
        StructField("name", StringType(), True),
        StructField("type", StringType(), True),
        StructField("creator", StringType(), True),
        StructField("movement", StringType(), True),
        StructField("country", StringType(), True),
        StructField("date", StringType(), True),
        StructField("material", StringType(), True),
        StructField("location", StringType(), True)
    ])

    # 2. Create DataFrame
    df = self.spark.createDataFrame(rows, schema)

    # 3. Deduplication
    df = df.dropDuplicates(["artwork"])

    # 4. Text cleaning with regex
    df = df.withColumn("name",
                       trim(regexp_replace(col("name"), r'[\"\n\r]', ' ')))
    df = df.withColumn("creator",
                       trim(regexp_replace(col("creator"), r'[\"\n\r]', ' ')))

    # 5. Add search indexes
    df = df.withColumn("name_lower", lower(col("name")))
    df = df.withColumn("movement_lower", lower(col("movement")))

    return df</code></pre>

            <p><strong>Transformation operations</strong>:</p>
            <ul>
                <li><strong>Explicit Schema</strong>: Avoids costly schema inference, improving performance</li>
                <li><strong>Deduplication</strong>: Removes duplicate artwork URIs using <code>dropDuplicates()</code></li>
                <li><strong>Text Cleaning</strong>: Uses <code>regexp_replace()</code> to remove special characters</li>
                <li><strong>Lowercase Indexing</strong>: Creates search-optimized columns for case-insensitive queries</li>
            </ul>

            <h4>7.2.3 Load Phase</h4>
            <p>
                Transformed data is loaded into two storage systems using batch processing:
            </p>

            <p><strong>Redis Batch Insert</strong>:</p>
            <pre><code>def load_to_redis(self, df):
    rows = df.collect()  # Collect to driver (small dataset)

    pipeline = self.cache.pipeline()  # Redis pipeline for batch
    for row in rows:
        obj = {
            "id": row["artwork"],
            "name": row["name"],
            "type": row["type"],
            # ... other fields
        }
        pipeline.rpush("art:all", json.dumps(obj))

    pipeline.execute()  # Single transaction</code></pre>

            <p><strong>Fuseki Batch Insert</strong>:</p>
            <pre><code>def load_to_fuseki(self, df):
    rows = df.collect()
    triples = []

    for row in rows:
        s = f"&lt;{row['artwork']}&gt;"
        triples.append(f'{s} a schema:VisualArtwork .')
        triples.append(f'{s} schema:name "{row["name"]}" .')
        # ... additional triples

    # Batch insert in chunks of 500
    chunk_size = 500
    for i in range(0, len(triples), chunk_size):
        chunk = triples[i:i+chunk_size]
        update_query = f"INSERT DATA {{ {' '.join(chunk)} }}"
        requests.post(fuseki_url, data={'update': update_query})</code></pre>

            <h4>7.2.4 Smart Fetch Logic</h4>
            <p>
                The ETL pipeline implements intelligent data fetching to avoid redundant processing:
            </p>
            <pre><code>def run(self):
    redis_has_data = self.cache.llen("art:all") > 100
    fuseki_has_data = self.count_fuseki_artworks() > 100

    if redis_has_data and fuseki_has_data:
        print("Both caches populated. Skipping ETL.")
        return

    if fuseki_has_data and not redis_has_data:
        print("Syncing Redis from Fuseki...")
        self.sync_redis_from_fuseki()
        return

    # Full ETL from Wikidata
    print("Running full ETL pipeline...")
    raw_data = self.extract_from_wikidata()
    df = self.transform_with_spark(raw_data)
    self.load_to_redis(df)
    self.load_to_fuseki(df)</code></pre>
        </section>

        <section id="spark-analytics">
            <h3>7.3 Spark Analytics Queries</h3>
            <p>
                The Analytics Service uses Spark DataFrames for real-time analytical queries,
                providing comparative analysis and similarity matching.
            </p>

            <h4>7.3.1 Comparative Analytics (/api/compare)</h4>
            <p>
                This endpoint compares music scenes between countries or genres using distributed Spark processing:
            </p>
            <pre><code>def compare_countries(country1, country2):
    # 1. Fetch data from Fuseki for both countries
    data1 = fetch_fuseki_data(country1)
    data2 = fetch_fuseki_data(country2)

    # 2. Create DataFrames with explicit schema
    schema = StructType([
        StructField("band", StringType(), True),
        StructField("location", StringType(), True),
        StructField("genre", StringType(), True),
        StructField("year", IntegerType(), True),
        StructField("target", StringType(), True)
    ])

    df1 = spark.createDataFrame(data1, schema)
    df2 = spark.createDataFrame(data2, schema)

    # 3. Analyze each group
    stats1 = analyze_group(df1, "country")
    stats2 = analyze_group(df2, "country")

    # 4. Calculate overlap (bands present in both)
    overlap = df1.join(df2, "band").count()

    # 5. Write to data lake for audit
    record = [{
        "ts": time.time(),
        "mode": "country",
        "t1": country1,
        "t2": country2,
        "overlap": overlap
    }]
    spark.createDataFrame(record).write.mode("append") \
        .parquet("/app/data_lake/comparisons")

    return {
        "data": {country1: stats1, country2: stats2},
        "overlap": overlap
    }</code></pre>

            <p><strong>Analysis Metrics Computed</strong>:</p>
            <pre><code>def analyze_group(df, mode):
    # Total count
    count_bands = df.count()

    # Diversity score (unique genres / total * 100)
    diversity = df.select("genre").distinct().count()
    diversity_score = (diversity / count_bands) * 100

    # Top distribution (GROUP BY + COUNT + ORDER BY + LIMIT)
    top_items = df.groupBy("genre").count() \
        .orderBy(col("count").desc()) \
        .limit(3).collect()

    # Temporal analysis
    year_df = df.filter(col("year").isNotNull())
    year_stats = year_df.select(
        avg("year").alias("avg_year"),
        spark_min("year").alias("oldest"),
        spark_max("year").alias("newest")
    ).collect()[0]

    # Decade breakdown
    decade_df = year_df.withColumn("decade",
                                    floor(col("year") / 10) * 10)
    decade_counts = decade_df.groupBy("decade").count() \
        .orderBy("decade").collect()

    # Genre uniqueness (rare genres < 5% of total)
    genre_counts = df.groupBy("genre").count().collect()
    rare_genres = sum(1 for row in genre_counts
                     if row['count'] < count_bands * 0.05)
    genre_uniqueness = (rare_genres / len(genre_counts)) * 100

    return {
        "total_bands": count_bands,
        "diversity_score": diversity_score,
        "top_distribution": top_items,
        "avg_founded_year": year_stats.avg_year,
        "era_range": f"{year_stats.oldest} - {year_stats.newest}",
        "decade_breakdown": decade_counts,
        "genre_uniqueness": genre_uniqueness
    }</code></pre>

            <h4>7.3.2 Similarity Matching (/api/similar)</h4>
            <p>
                Uses Spark to find similar bands based on genre matching:
            </p>
            <pre><code>def find_similar_bands(band_name):
    # 1. Load all bands into DataFrame
    all_data = fetch_all_bands_from_fuseki()
    df = spark.createDataFrame(all_data, schema)

    # 2. Find target band's genre
    target_row = df.filter(lower(col("name")) == band_name.lower()).first()
    target_genre = target_row['genre']

    # 3. Filter similar bands (same genre, different name)
    similar_df = df.filter(
        (lower(col("genre")) == target_genre.lower()) &
        (lower(col("name")) != band_name.lower())
    ).limit(5)

    # 4. Collect and return
    return similar_df.collect()</code></pre>

            <h4>7.3.3 Natural Language Search</h4>
            <p>
                Combines NLP parsing with Spark aggregations:
            </p>
            <pre><code># 1. NLP Parsing (regex extraction)
location_match = re.search(r'\b(in|from)\s+([a-zA-Z\s]+?)(?=\s+in\s+the\s+last|\s*$)', query)
years_match = re.search(r'last\s+(\d+)\s+years', query)

# 2. Dynamic SPARQL with filters
WHERE {
    ?band schema:location ?location .
    FILTER contains(lcase(str(?location)), lcase("United Kingdom"))

    OPTIONAL { ?band dbo:activeYearsStartYear ?startYear }
    FILTER (!BOUND(?startYear) || ?startYear >= 2004)

    ?band schema:genre ?genre .
}
GROUP BY ?genre
ORDER BY DESC(COUNT(?band))

# 3. Execute and aggregate with Spark if needed</code></pre>
        </section>

        <section id="spark-dataframes">
            <h3>7.4 DataFrame Schemas</h3>
            <p>
                BiR uses explicit DataFrame schemas for type safety and performance optimization:
            </p>

            <h4>7.4.1 Music Domain Schema</h4>
            <pre><code>music_schema = StructType([
    StructField("band", StringType(), True),      # Wikidata URI
    StructField("location", StringType(), True),  # Country of origin
    StructField("genre", StringType(), True),     # Music genre
    StructField("year", IntegerType(), True),     # Founding year
    StructField("target", StringType(), True)     # Target entity for comparison
])</code></pre>

            <h4>7.4.2 Art Domain Schema</h4>
            <pre><code>art_schema = StructType([
    StructField("artwork", StringType(), True),   # Wikidata URI
    StructField("name", StringType(), True),      # Artwork title
    StructField("type", StringType(), True),      # Art form (painting, sculpture, etc.)
    StructField("creator", StringType(), True),   # Artist name
    StructField("movement", StringType(), True),  # Art movement
    StructField("country", StringType(), True),   # Country where created
    StructField("date", StringType(), True),      # Creation date
    StructField("material", StringType(), True),  # Medium/material
    StructField("location", StringType(), True)   # Current location
])</code></pre>

            <p>
                <strong>Schema Benefits</strong>:
            </p>
            <ul>
                <li>Type safety: Enforces data types at DataFrame creation</li>
                <li>Performance: Avoids costly schema inference from data</li>
                <li>Documentation: Serves as self-documenting data model</li>
                <li>Consistency: Ensures uniform data structure across pipeline</li>
            </ul>
        </section>

        <section id="data-lake">
            <h3>7.5 Data Lake Architecture</h3>
            <p>
                BiR implements a data lake for historical analytics and audit trails,
                storing comparison results in Apache Parquet format.
            </p>

            <h4>7.5.1 Storage Structure</h4>
            <pre><code>/app/data_lake/
└── comparisons/
    ├── part-00000-*.snappy.parquet
    ├── part-00001-*.snappy.parquet
    ├── .part-*.crc
    └── _SUCCESS</code></pre>

            <h4>7.5.2 Parquet Schema</h4>
            <pre><code>comparison_schema = StructType([
    StructField("ts", DoubleType(), False),       # Timestamp (Unix epoch)
    StructField("mode", StringType(), False),     # "country" or "genre"
    StructField("t1", StringType(), False),       # First entity
    StructField("t2", StringType(), False),       # Second entity
    StructField("overlap", IntegerType(), False)  # Number of common bands
])</code></pre>

            <h4>7.5.3 Write Operations</h4>
            <pre><code># Append mode for incremental storage
spark.createDataFrame(records, comparison_schema) \
    .write \
    .mode("append") \
    .parquet("/app/data_lake/comparisons")</code></pre>

            <p><strong>Parquet Advantages</strong>:</p>
            <ul>
                <li><strong>Compression</strong>: Snappy compression reduces storage by ~70%</li>
                <li><strong>Columnar Format</strong>: Efficient for analytical queries</li>
                <li><strong>Schema Evolution</strong>: Supports adding new fields</li>
                <li><strong>Hadoop Compatibility</strong>: Integrates with big data ecosystem</li>
            </ul>
        </section>

        <section id="spark-optimizations">
            <h3>7.6 Performance Optimizations</h3>
            <p>
                The Spark implementation incorporates several optimization techniques for
                efficient processing of music and art datasets.
            </p>

            <h4>7.6.1 Explicit Schema Definition</h4>
            <p>
                All DataFrames use explicit schemas to avoid expensive schema inference:
            </p>
            <pre><code># BAD: Schema inference (slow)
df = spark.createDataFrame(data)

# GOOD: Explicit schema (fast)
df = spark.createDataFrame(data, schema)</code></pre>

            <h4>7.6.2 Batch Processing</h4>
            <p>
                Data is processed in optimized batches to reduce network overhead:
            </p>
            <ul>
                <li><strong>Redis Pipeline</strong>: Batches all inserts into single transaction</li>
                <li><strong>Fuseki Chunks</strong>: Inserts RDF triples in chunks of 500 to avoid timeouts</li>
                <li><strong>Parquet Partitions</strong>: Data lake files partitioned for parallel reads</li>
            </ul>

            <h4>7.6.3 Memory Management</h4>
            <pre><code># Conservative memory allocation
spark.driver.memory = 1-2 GB
spark.executor.memory = 1 GB

# Early filtering to reduce data size
df = df.filter(col("year").isNotNull())  # Before collect()
df = df.limit(10000)  # Prevent OOM on large queries</code></pre>

            <h4>7.6.4 Caching Strategies</h4>
            <ul>
                <li><strong>Redis Cache</strong>: Frequently accessed search results cached for instant retrieval</li>
                <li><strong>Smart Fetch</strong>: ETL skips Wikidata query if local data exists</li>
                <li><strong>Lazy Evaluation</strong>: Spark transformations only execute when action is called</li>
            </ul>

            <h4>7.6.5 Query Optimization</h4>
            <pre><code># Use filters early in pipeline
df.filter(condition).groupBy(...).count()  # Efficient

# NOT: groupBy before filter
df.groupBy(...).count().filter(condition)  # Inefficient

# Avoid collect() on large datasets
result = df.take(100)  # Better: limit before collect
# NOT: df.collect()  # Dangerous: all data to driver</code></pre>

            <p><strong>Performance Results</strong>:</p>
            <ul>
                <li>ETL processing: 2-5 minutes for 3000 artworks</li>
                <li>Comparison query: 2-5 seconds for two countries</li>
                <li>Similarity search: <1 second for 2000 bands</li>
                <li>Data lake write: <500ms per comparison record</li>
            </ul>
        </section>
    </section>

    <section id="user-interface">
        <h2>8. User Interface and Visual Features</h2>

        <section id="artwork-search-interface">
            <h3>8.1 Artwork Search Interface</h3>
            <p>
                The Fine Arts search interface provides a semantic search experience for exploring artworks
                from the Knowledge Graph. Users can search by movement, artist, or artwork title with instant
                results rendered as interactive cards.
            </p>

            <figure>
                <img src="screenshot-art-search.png" alt="Artwork Search interface showing Impressionism search results with 12 artworks displayed as cards" style="width: 100%; max-width: 900px; border: 1px solid #ddd; padding: 10px; background: white;">
                <figcaption>
                    <strong>Figure 4</strong>: Artwork Search Interface - The user searches for "Impressionism" and receives
                    12 results displayed as SemanticCard components. Each card shows:
                    <ul>
                        <li><strong>Artwork Icon</strong>: Visual indicator for art domain</li>
                        <li><strong>Title</strong>: "The Kiss", "Pont...", "Garden...", "Salisbury..."</li>
                        <li><strong>Artist & Movement</strong>: Auguste Rodin, Camille Pissarro, Claude Monet, John Constable</li>
                        <li><strong>Type</strong>: sculpture, painting (with Schema.org classification)</li>
                        <li><strong>Country</strong>: Unknown, France, United Kingdom</li>
                        <li><strong>Location</strong>: Luxembourg Museum, Art Gallery of Ontario, Metropolitan Museum of Art, Salisbury Museum</li>
                        <li><strong>Find Similar Button</strong>: Triggers recommendation algorithm</li>
                    </ul>
                    The interface includes export options (JSON, CSV) and "Show Graph" button for network visualization.
                    The search uses RDF data from Fuseki with full-text matching on artwork names and movements.
                </figcaption>
            </figure>

            <p><strong>Technical Implementation</strong>:</p>
            <ul>
                <li><strong>Component</strong>: <code>ArtCard.jsx</code> with RDFa markup</li>
                <li><strong>API Endpoint</strong>: <code>GET /api/art?q=Impressionism</code></li>
                <li><strong>Data Source</strong>: Redis cache with fallback to Fuseki SPARQL</li>
                <li><strong>Schema.org Integration</strong>: Each card embeds VisualArtwork metadata</li>
            </ul>
        </section>

        <section id="network-graph-visualization">
            <h3>8.2 Network Graph Visualization</h3>
            <p>
                The network graph provides an interactive visualization of relationships between artists,
                art movements, and countries in the Knowledge Graph, powered by vis-network library.
            </p>

            <figure>
                <img src="screenshot-network-impressionism.png" alt="Network graph showing Impressionism movement connections with artists and countries" style="width: 100%; max-width: 900px; border: 1px solid #ddd; padding: 10px; background: white;">
                <figcaption>
                    <strong>Figure 5</strong>: Network Graph - Impressionism Movement Visualization. The graph displays
                    14 nodes and their relationships:
                    <ul>
                        <li><strong>Movement Node</strong> (yellow diamond): "Impressionism" - central hub</li>
                        <li><strong>Artist Nodes</strong> (blue circles): Auguste Rodin, Claude Monet, Pierre-Auguste Renoir, John Constable, Lazare Loustau, Georges Seurat, Vincent van Gogh, Lilla Cabot</li>
                        <li><strong>Country Node</strong> (green square): "United Kingdom"</li>
                        <li><strong>Artwork Nodes</strong> (listed in sidebar): "The Kiss" (Auguste Rodin), "Garden at Sainte-Adresse" (Claude Monet)</li>
                    </ul>
                    The sidebar panel shows:
                    <ul>
                        <li><strong>Movement Info</strong>: "Impressionism" with 4 connections</li>
                        <li><strong>Connected Artists</strong>: Clickable artist names (Auguste Rodin, Claude Monet, John Constable, Pierre-Auguste Renoir)</li>
                        <li><strong>Artworks</strong>: 9 artworks listed with URIs and museum locations</li>
                    </ul>
                    Users can filter nodes by type (Artists, Movements, Countries) and export the graph as PNG.
                    The graph uses physics simulation for organic layout with draggable nodes.
                </figcaption>
            </figure>

            <p><strong>Technical Implementation</strong>:</p>
            <ul>
                <li><strong>Component</strong>: <code>NetworkGraph.jsx</code> using vis-network</li>
                <li><strong>Data Structure</strong>: Nodes (artists, movements, countries) and Edges (relationships)</li>
                <li><strong>Physics Engine</strong>: BarnesHut algorithm for force-directed layout</li>
                <li><strong>Export</strong>: Canvas to PNG conversion for sharing</li>
            </ul>

            <figure>
                <img src="screenshot-network-post-impressionism.png" alt="Network graph showing Post-impressionism movement with Van Gogh, Monet, Seurat, and Pissarro" style="width: 100%; max-width: 900px; border: 1px solid #ddd; padding: 10px; background: white;">
                <figcaption>
                    <strong>Figure 6</strong>: Network Graph - Post-impressionism Movement. This graph shows a different
                    art movement with distinct connections:
                    <ul>
                        <li><strong>Movement Node</strong> (yellow diamond): "Post-impressionism"</li>
                        <li><strong>Artists</strong>: Vincent van Gogh, Camille Pissarro, Claude Monet, Georges Seurat</li>
                        <li><strong>Artworks</strong>: "Bathers at Asnières" (Georges Seurat), "Starry Night Over the Rhone" (Vincent van Gogh)</li>
                    </ul>
                    The sidebar displays 2 connections and 2 artworks with full metadata (URIs, locations: National Gallery, Musée d'Orsay).
                    This demonstrates how different movements connect different sets of artists, enabling discovery
                    of artistic influence patterns across the Knowledge Graph.
                </figcaption>
            </figure>
        </section>

        <section id="spark-comparative-analytics">
            <h3>8.3 Spark-Powered Comparative Analytics</h3>
            <p>
                The comparative analytics feature uses Apache Spark to perform distributed analysis
                of music trends across countries or genres, providing insights into diversity, productivity,
                and temporal patterns.
            </p>

            <figure>
                <img src="screenshot-spark-compare.png" alt="Spark comparison results showing United States vs United Kingdom music scene analysis" style="width: 100%; max-width: 900px; border: 1px solid #ddd; padding: 10px; background: white;">
                <figcaption>
                    <strong>Figure 7</strong>: Spark Comparative Analysis Results - United States vs United Kingdom.
                    The analysis interface shows:
                    <ul>
                        <li><strong>Comparison Summary Cards</strong>:
                            <ul>
                                <li>"Most Diverse": United Kingdom (72.1% diversity score)</li>
                                <li>"Most Prolific": United States (157 total bands vs 61 for UK)</li>
                                <li>"Oldest Scene": United Kingdom (avg founded 1980 vs 1988 for US)</li>
                            </ul>
                        </li>
                        <li><strong>Genre Analysis</strong>:
                            <ul>
                                <li>Common Genres: blues rock, alternative rock, hard rock, new wave, glam rock</li>
                                <li>US Unique: dance-punk, digital hardcore, reggae rock</li>
                                <li>UK Unique: dance music, chamber pop, art pop</li>
                            </ul>
                        </li>
                        <li><strong>Detailed Statistics per Country</strong>:
                            <ul>
                                <li>United States: 157 bands, 46.5% diversity, avg founded 1988, ERA 1963-2010, most productive 1990s (47 bands)</li>
                                <li>United Kingdom: 61 bands, 72.1% diversity, avg founded 1980, ERA 1960-2010, most productive 1980s (26 bands)</li>
                            </ul>
                        </li>
                        <li><strong>Temporal Timeline</strong>: Clickable decade badges (1960s, 1970s, 1980s, 1990s, 2000s, 2010s)</li>
                        <li><strong>Top Genres List</strong>: Ranked with counts (alternative rock: 9, folk rock: 3)</li>
                    </ul>
                    This analysis is computed using Spark DataFrames with GROUP BY, COUNT, AVG aggregations,
                    and the results are persisted to the data lake in Parquet format for audit trails.
                </figcaption>
            </figure>

            <p><strong>Spark Processing Details</strong>:</p>
            <pre><code># 1. Fetch data from Fuseki for both countries
data_us = fetch_fuseki_data("United States")  # 157 bands
data_uk = fetch_fuseki_data("United Kingdom")  # 61 bands

# 2. Create DataFrames with schema
df_us = spark.createDataFrame(data_us, music_schema)
df_uk = spark.createDataFrame(data_uk, music_schema)

# 3. Calculate diversity (unique genres / total * 100)
diversity_us = df_us.select("genre").distinct().count() / 157 * 100  # 46.5%
diversity_uk = df_uk.select("genre").distinct().count() / 61 * 100   # 72.1%

# 4. Decade breakdown
df_us.withColumn("decade", floor(col("year") / 10) * 10) \
     .groupBy("decade").count() \
     .orderBy("decade")

# 5. Write to data lake
spark.createDataFrame([{
    "ts": time.time(),
    "mode": "country",
    "t1": "United States",
    "t2": "United Kingdom",
    "overlap": 0
}]).write.mode("append").parquet("/app/data_lake/comparisons")</code></pre>
        </section>

        <section id="music-entity-search">
            <h3>8.4 Music Entity Search and Recommendations</h3>
            <p>
                The music search interface provides instant access to band information with
                Spark-powered similarity recommendations based on genre matching.
            </p>

            <figure>
                <img src="screenshot-music-search.png" alt="Music search results showing rock bands with search bar and entity cards" style="width: 100%; max-width: 900px; border: 1px solid #ddd; padding: 10px; background: white;">
                <figcaption>
                    <strong>Figure 8</strong>: Music Entity Search Interface. The search bar shows "rock" query
                    with 5 results found:
                    <ul>
                        <li><strong>U2</strong> - soft rock (with "Find Similar" button)</li>
                        <li><strong>Q1299</strong> - hard rock (with "Find Similar" button)</li>
                        <li><strong>Birds of Tokyo</strong> - alternative rock (with "Hide Similars" expanded showing recommendations:
                            <ul>
                                <li>Linkin Park - matches genre: alternative rock</li>
                                <li>U2 - matches genre: alternative rock</li>
                                <li>Red Hot Chili Peppers - matches genre: alternative rock</li>
                                <li>Tame Impala - matches genre: alternative rock</li>
                                <li>No Doubt - matches genre: alternative rock</li>
                            </ul>
                        )</li>
                        <li><strong>Lawson</strong> - pop rock (with "Find Similar" button)</li>
                    </ul>
                    The recommendation system uses Spark to filter bands by matching genre from the full dataset,
                    demonstrating the Linked Data principle of discovering related resources.
                </figcaption>
            </figure>

            <p><strong>Recommendation Algorithm</strong>:</p>
            <pre><code>def find_similar_bands(target_band):
    # 1. Load all 2000+ bands into Spark DataFrame
    all_bands_df = spark.createDataFrame(fetch_all_bands(), music_schema)

    # 2. Find target band's genre
    target = all_bands_df.filter(
        lower(col("name")) == target_band.lower()
    ).first()

    # 3. Filter by same genre, exclude target
    similar = all_bands_df.filter(
        (lower(col("genre")) == target['genre'].lower()) &
        (col("name") != target_band)
    ).limit(5)

    # 4. Return with reason
    return [{
        "name": row['name'],
        "genre": row['genre'],
        "reason": f"matches genre: {row['genre']}"
    } for row in similar.collect()]</code></pre>
        </section>

        <section id="natural-language-search">
            <h3>8.5 Natural Language Semantic Search</h3>
            <p>
                The platform includes a natural language search interface that parses user queries
                in plain English and translates them into SPARQL queries with semantic intent extraction.
            </p>

            <figure>
                <img src="screenshot-nlp-search.png" alt="Natural language search showing 'music trends in Germany' with parsed intent and genre results" style="width: 100%; max-width: 900px; border: 1px solid #ddd; padding: 10px; background: white;">
                <figcaption>
                    <strong>Figure 9</strong>: Natural Language Search Interface. User enters the query
                    "music trends in Germany" and the system:
                    <ul>
                        <li><strong>Parses Intent</strong>: Displays purple badges showing extracted parameters:
                            <ul>
                                <li>"germany" (location filter)</li>
                                <li>"All time" (temporal scope)</li>
                            </ul>
                        </li>
                        <li><strong>Top Results Found</strong>: Genre distribution badges with counts:
                            <ul>
                                <li>power metal (1 band)</li>
                                <li>Eurodisco (1)</li>
                                <li>thrash metal (1)</li>
                                <li>Eurodance (2)</li>
                                <li>heavy metal (1)</li>
                                <li>synth-pop (2)</li>
                                <li>techno (2)</li>
                                <li>German punk (1)</li>
                            </ul>
                        </li>
                    </ul>
                    The NLP engine uses regex patterns to extract location and time period, then generates a
                    SPARQL query with FILTER clauses to query the Fuseki Knowledge Graph. Results are aggregated
                    by genre using GROUP BY and ORDER BY clauses.
                </figcaption>
            </figure>

            <p><strong>NLP Query Processing Pipeline</strong>:</p>
            <pre><code># 1. Extract intent from natural language
query = "music trends in Germany"

location_match = re.search(
    r'\b(in|from)\s+([a-zA-Z\s]+?)(?=\s+in\s+the\s+last|\s*$)',
    query
)
location = location_match.group(2).strip()  # "Germany"

years_match = re.search(r'last\s+(\d+)\s+years', query)
time_period = "All time" if not years_match else f"Last {years_match.group(1)} years"

# 2. Generate SPARQL with semantic filters
sparql_query = f"""
PREFIX schema: <http://schema.org/>
PREFIX dbo: <http://dbpedia.org/ontology/>

SELECT ?genre (COUNT(?band) AS ?count)
WHERE {{
    ?band a schema:MusicGroup .
    ?band schema:location ?location .
    FILTER contains(lcase(str(?location)), lcase("{location}"))

    ?band schema:genre ?genre .
}}
GROUP BY ?genre
ORDER BY DESC(?count)
"""

# 3. Execute against Fuseki
results = fuseki.query(sparql_query)

# 4. Return aggregated genre distribution</code></pre>

            <p><strong>Example Queries Supported</strong>:</p>
            <ul>
                <li>"bands in United Kingdom in the last 20 years"</li>
                <li>"music styles in United States from the last 26 years"</li>
                <li>"influences from United States"</li>
                <li>"music trends in Germany" (shown above)</li>
            </ul>

            <p>
                This feature demonstrates the power of combining NLP, SPARQL, and semantic web technologies
                to provide intuitive access to structured Knowledge Graph data.
            </p>
        </section>

        <section id="advanced-analytics-engine">
            <h3>8.6 Advanced Analytics Engine Interface</h3>
            <p>
                The BiR Analytics platform provides a comprehensive interface for exploring music data
                through both simple entity search and advanced Spark-powered comparative analytics.
            </p>

            <figure>
                <img src="screenshot-analytics-interface.png" alt="BiR Analytics main interface with entity search, global stats, and Advanced Analytics Engine" style="width: 100%; max-width: 900px; border: 1px solid #ddd; padding: 10px; background: white;">
                <figcaption>
                    <strong>Figure 10</strong>: BiR Analytics Main Interface. The landing page shows:
                    <ul>
                        <li><strong>Header</strong>: "BiR Analytics - Big Data Retriever & Spark Engine" with domain tabs (Music, Fine Arts)</li>
                        <li><strong>Entity Search</strong>: Large search input with "rock" example query and blue "Search" button</li>
                        <li><strong>Global Stats Card</strong>: "Real-time Fuseki Data" panel (left sidebar)</li>
                        <li><strong>Advanced Analytics Engine</strong>: Purple gradient section with:
                            <ul>
                                <li>Description: "Selectează dimensiunea analizei și entitățile pe care vrei să le compari folosind Apache Spark"</li>
                                <li>Two analysis mode buttons:
                                    <ul>
                                        <li>"Compare Countries" (blue with globe icon)</li>
                                        <li>"Compare Genres" (pink with guitar icon)</li>
                                    </ul>
                                </li>
                                <li>Entity input fields:
                                    <ul>
                                        <li>"ENTITY A": "United States"</li>
                                        <li>"ENTITY B": "United Kingdom"</li>
                                    </ul>
                                </li>
                                <li>"RUN SPARK" button (purple) to trigger distributed analysis</li>
                            </ul>
                        </li>
                    </ul>
                    This interface serves as the entry point for both simple searches and complex Spark-powered
                    comparative analytics, demonstrating the dual nature of the platform: quick entity lookup
                    and deep analytical insights.
                </figcaption>
            </figure>

            <p><strong>Interface Components</strong>:</p>
            <ul>
                <li><strong>Entity Search</strong>: Queries Redis cache for instant results (sub-100ms)</li>
                <li><strong>Global Stats</strong>: Real-time SPARQL COUNT queries to Fuseki</li>
                <li><strong>Compare Countries</strong>: Spark analysis by geographic location (section 7.3.1)</li>
                <li><strong>Compare Genres</strong>: Spark analysis by music style (same algorithm, different dimension)</li>
                <li><strong>RUN SPARK Button</strong>: Triggers POST to <code>/api/compare?mode=country&t1=...&t2=...</code></li>
            </ul>
        </section>
    </section>

    <section id="conclusion">
        <h2>9. Conclusion</h2>
        <p>
            BiR successfully demonstrates the practical application of semantic web technologies
            for building knowledge graphs from open data sources. The system:
        </p>
        <ul>
            <li>Uses RDF data models based on Schema.org vocabulary</li>
            <li>Implements RESTful APIs following microservices architecture</li>
            <li>Integrates with Wikidata and DBpedia knowledge bases</li>
            <li>Conforms to Linked Data principles</li>
            <li>Leverages Apache Spark for distributed big data processing</li>
            <li>Provides practical use cases for Music and Fine Arts domains</li>
        </ul>
        <p>
            The technical implementation leverages modern technologies (React, Flask, Apache Spark, Fuseki)
            to create a scalable, maintainable system that demonstrates the power of semantic web
            technologies combined with big data processing for knowledge management and advanced analytics.
        </p>
    </section>

    <section id="references">
        <h2>10. References</h2>
        <ol>
            <li>Schema.org. (2024). <em>Schema.org Vocabulary</em>. Retrieved from <a href="https://schema.org/">https://schema.org/</a></li>
            <li>Wikidata. (2024). <em>Wikidata: The Free Knowledge Base</em>. Retrieved from <a href="https://www.wikidata.org/">https://www.wikidata.org/</a></li>
            <li>W3C. (2013). <em>SPARQL 1.1 Query Language</em>. W3C Recommendation. Retrieved from <a href="https://www.w3.org/TR/sparql11-query/">https://www.w3.org/TR/sparql11-query/</a></li>
            <li>Berners-Lee, T. (2006). <em>Linked Data</em>. Retrieved from <a href="https://www.w3.org/DesignIssues/LinkedData.html">https://www.w3.org/DesignIssues/LinkedData.html</a></li>
            <li>Apache Jena. (2024). <em>Apache Jena Fuseki</em>. Retrieved from <a href="https://jena.apache.org/documentation/fuseki2/">https://jena.apache.org/documentation/fuseki2/</a></li>
            <li>DBpedia. (2024). <em>DBpedia Ontology</em>. Retrieved from <a href="https://www.dbpedia.org/resources/ontology/">https://www.dbpedia.org/resources/ontology/</a></li>
        </ol>
    </section>

    <footer>
        <p>
            <small>This document is part of the BiR (Big Data Retriever) project documentation.</small>
        </p>
    </footer>
</body>
</html>
